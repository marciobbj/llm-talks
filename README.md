# LLM Talks ü§ñüí¨ü§ñ

**LLM Talks** √© uma ferramenta que coloca dois modelos de Intelig√™ncia Artificial para conversar entre si sobre qualquer assunto que voc√™ definir. 

O projeto foi desenhado para ser **extremamente flex√≠vel**, permitindo o uso de:
- **Modelos Locais** (via Ollama, LocalAI, etc.)
- **Modelos em Nuvem** (OpenRouter, OpenAI, etc.)
- **Configura√ß√µes H√≠bridas** (ex: GPT-4 conversando com Llama 3 localmente)

Possui uma interface web moderna, focada na legibilidade e simplicidade.

## Funcionalidades

- **Batalha de IAs**: Coloque perspectivas diferentes (persona Curiosa vs C√©tica) para debater.
- **Interface Otimizada**: Design limpo, com fontes grandes e alto contraste para f√°cil leitura.
- **Flexibilidade Total**: Configure URLs base e chaves de API independentes para cada modelo.
- **Modo CLI**: Tamb√©m pode ser executado diretamente no terminal.

## Instala√ß√£o

1. **Clone o reposit√≥rio** e entre na pasta:
   ```bash
   git clone https://github.com/seu-usuario/llm-talks.git
   cd llm-talks
   ```

2. **Crie um ambiente virtual (Recomendado)**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # No Windows: venv\Scripts\activate
   ```

3. **Instale as depend√™ncias**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure o ambiente**:
   Copie o exemplo e edite com suas chaves:
   ```bash
   cp .env.example .env
   ```

## Configura√ß√£o (.env)

O arquivo `.env` na raiz do projeto gerencia os modelos.

**Exemplo: Dois Modelos Locais (Ollama)**
```ini
# Modelo A
MODEL_A_NAME=llama3
MODEL_A_API_KEY=ollama
MODEL_A_BASE_URL=http://localhost:11434/v1

# Modelo B
MODEL_B_NAME=mistral
MODEL_B_API_KEY=ollama
MODEL_B_BASE_URL=http://localhost:11434/v1
```

## üñ•Ô∏è Como Usar

### Interface Web
1. Inicie o servidor Flask:
   ```bash
   python app.py
   ```
2. Acesse **[http://localhost:5000](http://localhost:5000)** no seu navegador.
3. Digite um t√≥pico e inicie a conversa.

### Linha de Comando (CLI)
Para rodar rapidamente no terminal, sem interface gr√°fica:
```bash
python llm_talks.py --topic "A √©tica na clonagem humana"
```

## Estrutura do Projeto

- `app.py`: Servidor Backend (Flask).
- `llm_talks.py`: L√≥gica central de controle da conversa.
- `templates/index.html`: Interface do usu√°rio.
- `static/css/styles.css`: Estilos otimizados.

## Contribui√ß√£o

Sinta-se √† vontade para abrir issues ou enviar PRs!
